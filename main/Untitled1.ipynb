{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e73223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SOURCE_LENGTH = 1024\n",
    "MAX_TARGET_LENGTH = 1024\n",
    "USES_PADDING = \"max_length\" #False\n",
    "DO_IGNORE_PAD_TOKEN_FOR_LOSS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e747dc79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSeq2SeqLM\n",
    "model_name = \"facebook/bart-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e75e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(data):\n",
    "        input_encodings = tokenizer.batch_encode_plus(data['text'], padding=USES_PADDING, truncation=True)\n",
    "        target_encodings = tokenizer.batch_encode_plus(data['logical_form'], padding=USES_PADDING, truncation=True)\n",
    "\n",
    "        labels = target_encodings['input_ids']\n",
    "        if USES_PADDING == \"max_length\" and DO_IGNORE_PAD_TOKEN_FOR_LOSS:\n",
    "            labels = [\n",
    "                [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels\n",
    "            ]\n",
    "\n",
    "        encodings = {\n",
    "            'input_ids': input_encodings['input_ids'],\n",
    "            'attention_mask': input_encodings['attention_mask'],\n",
    "            'labels': labels,\n",
    "        }\n",
    "        return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59d37a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCLUDE_TYPES = ['designates_at_that', 'is_a_party_of', 'is_a_member_of', 'is_a_small_business_entity_as_informed_by', 'it_is_the_end_of', 'has_paid_itself', 'end_of_the_world']\n",
    "SATOH_DATAPATH = '../Datasets/pair_synset_by_lesk.txt'\n",
    "\n",
    "import re\n",
    "from time import sleep\n",
    "import torch\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "\n",
    "def get_satoh_data_unseen(val_percentage=0.1):\n",
    "    with open(SATOH_DATAPATH, 'r') as datastream:\n",
    "        raw_data = datastream.readlines()\n",
    "    \n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for line in raw_data:\n",
    "        i = 0\n",
    "        indices = []\n",
    "        while len(indices) < 4:\n",
    "            i += line[i:].find(\"\\\"\") + 1\n",
    "            indices.append(i)\n",
    "\n",
    "        x_data.append(line[indices[2]:indices[3] - 1])\n",
    "        y_data.append(line[indices[0]:indices[1] - 1])\n",
    "        \n",
    "    unseen_x = []\n",
    "    unseen_y = []\n",
    "    for i, point in enumerate(y_data):\n",
    "        name = point[:point.find(\"(\")]\n",
    "        if name in EXCLUDE_TYPES:\n",
    "            unseen_x.append(x_data[i])\n",
    "            unseen_y.append(point)\n",
    "            \n",
    "    for i, point in enumerate(unseen_x):\n",
    "        x_data.remove(point)\n",
    "        y_data.remove(unseen_y[i])\n",
    "                    \n",
    "    pre_dataset = {\"text\": x_data, \"logical_form\": y_data}\n",
    "    \n",
    "    dataset = Dataset.from_dict(pre_dataset)\n",
    "    unseen_dataset = Dataset.from_dict({\"text\": unseen_x, \"logical_form\": unseen_y})\n",
    "    \n",
    "    val_size = int(val_percentage * len(dataset))\n",
    "    test_size = 50\n",
    "    train_size = len(dataset) - val_size - test_size\n",
    "\n",
    "    dataset_dict = dataset.train_test_split(train_size=train_size, test_size=(val_size + test_size))\n",
    "    test_val_dict = dataset_dict[\"test\"].train_test_split(train_size=val_size, test_size=test_size)\n",
    "    \n",
    "    dataset_dict[\"val\"] = test_val_dict[\"train\"]\n",
    "    dataset_dict[\"test\"] = test_val_dict[\"test\"]\n",
    "    dataset_dict[\"test\"] = unseen_dataset#concatenate_datasets([dataset_dict[\"test\"], unseen_dataset])\n",
    "    \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc6f9c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42e1fce72d84bf081b397f970f30971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a04137911a3418883a27cb2c2822e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e830c1f7186543dab880ca98c4752a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = get_satoh_data_unseen()\n",
    "datasets = datasets.map(preprocess_function, batched=True)\n",
    "columns = ['input_ids', 'labels','attention_mask',] \n",
    "datasets.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "688c5ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(dataset, trainer, tokenizer, limit=50):\n",
    "    results = []\n",
    "    original_texts = []\n",
    "    original_logical_forms = []\n",
    "    predicted_logical_forms = []\n",
    "    split_dataset = dataset.train_test_split(train_size=1, test_size=(len(dataset) - 1))\n",
    "    \n",
    "    for i in range(len(dataset) - 2):\n",
    "        results.append(trainer.predict(split_dataset[\"train\"]).predictions)\n",
    "        original_logical_forms.append(split_dataset[\"train\"][\"logical_form\"][0])\n",
    "        original_texts.append(split_dataset[\"train\"][\"text\"][0])\n",
    "        split_dataset = split_dataset[\"test\"].train_test_split(train_size=1, test_size=(len(dataset) - 2 - i))\n",
    "        if i == limit - 3:\n",
    "            break\n",
    "        \n",
    "    results.append(trainer.predict(split_dataset[\"train\"]).predictions)\n",
    "    if split_dataset[\"test\"].num_rows == 1:\n",
    "        results.append(trainer.predict(split_dataset[\"test\"]).predictions)\n",
    "    \n",
    "    original_logical_forms.append(split_dataset[\"train\"][\"logical_form\"][0])\n",
    "    original_logical_forms.append(split_dataset[\"test\"][\"logical_form\"][0])\n",
    "    \n",
    "    \n",
    "    original_texts.append(split_dataset[\"train\"][\"text\"][0])\n",
    "    original_texts.append(split_dataset[\"test\"][\"text\"][0])\n",
    "    \n",
    "    for result in results:\n",
    "        text = []\n",
    "        for value in result[0][0][1:]:\n",
    "            _lst = list(value)\n",
    "            _id = _lst.index(max(_lst))\n",
    "            chunk = tokenizer.convert_ids_to_tokens(_id)\n",
    "            if chunk == \"</s>\":\n",
    "                break\n",
    "                \n",
    "            text.append(chunk)\n",
    "        \n",
    "        predicted_logical_forms.append(\"\".join(text))\n",
    "        \n",
    "    return original_texts, original_logical_forms, predicted_logical_forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b5ed90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./models/' + model_name + \"-legal-unseen\",          \n",
    "    num_train_epochs=5,           \n",
    "    per_device_train_batch_size=1, \n",
    "    per_device_eval_batch_size=1,   \n",
    "    warmup_steps=100,               \n",
    "    weight_decay=0.01,              \n",
    "    logging_dir='./logs',  \n",
    "    save_steps=5000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "188a516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model = model.from_pretrained(\"../trained_models/bart-satoh-unseen\")\n",
    "trainer = Trainer(\n",
    "model=our_model,                       \n",
    "args=training_args,                  \n",
    "train_dataset=datasets['train'],        \n",
    "eval_dataset=datasets['val']   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c2da75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 02:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n"
     ]
    }
   ],
   "source": [
    "split = datasets[\"test\"].train_test_split(train_size=37, test_size=37)\n",
    "\n",
    "original_texts1, original_logical_forms1, predicted_logical_forms1 = batch_predict(split[\"train\"], trainer, tokenizer, limit=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d82c9bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n"
     ]
    }
   ],
   "source": [
    "original_texts2, original_logical_forms2, predicted_logical_forms2 = batch_predict(split[\"test\"], trainer, tokenizer, limit=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40c5944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_texts = original_texts1 + original_texts2\n",
    "original_logical_forms = original_logical_forms1 + original_logical_forms2\n",
    "predicted_logical_forms = predicted_logical_forms1 + predicted_logical_forms2\n",
    "\n",
    "predicted_logical_forms = [pred.replace(\"Ġ\", \" \") for pred in predicted_logical_forms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e60693f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list(zip(original_texts, original_logical_forms, predicted_logical_forms)), columns=['Original Texts', 'Original logical forms', 'Predicted logical forms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a9f40a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"predicted_test_dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444440c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "juris-env",
   "language": "python",
   "name": "juris-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
